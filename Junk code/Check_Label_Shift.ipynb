{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file is a collection of all the graphing & prediction code i have used in my bachelors project.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import JaccardIndex, MulticlassAccuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import torch.nn.functional as F\n",
    "from empatches import BatchPatching\n",
    "\n",
    "import os\n",
    "from imutils import paths\n",
    "from files import config\n",
    "\n",
    "file_path = os.getcwd()\n",
    "\n",
    "def prepare_plot(origImage, origMask, predMask, conf, it):\n",
    "    figure, ax = plt.subplots(nrows=int(len(origImage) / 2), ncols=4, figsize=(50, 35), gridspec_kw={'width_ratios': [1, 2.34, 1, 2.34]})\n",
    "    cmap = mcolors.ListedColormap(['white', 'blue', 'maroon', 'black', 'darkgreen'])\n",
    "    norm = Normalize(vmin=0.0, vmax=4.0)\n",
    "    n = 0\n",
    "\n",
    "    for j in range(int(len(origImage) / 2)):\n",
    "        for i in range(2):\n",
    "            predMask[int(n)] = predMask[n].squeeze()\n",
    "\n",
    "            ax[j, 1 + int(2 * i)].imshow(origImage[n])\n",
    "            ax[j, 1 + int(2 * i)].set_title(f\"Original Image with Prediction mask ({1 + n})\", fontsize=32)\n",
    "            ax[j, 1 + int(2 * i)].axis('off')\n",
    "\n",
    "            cb = ax[j, 1 + int(2 * i)].imshow(origMask[n], interpolation=\"none\", cmap=cmap, norm=norm, alpha=0.35)\n",
    "            cbar = figure.colorbar(cb, ax=ax[j, 1 + int(2 * i)], ticks=[0.4, 1.2, 2, 2.8, 3.6], pad=0.025, shrink=0.9)\n",
    "            cbar.ax.set_yticklabels(['Sea', 'Oil', 'LoA', 'Ship', 'Land'], fontsize=20)\n",
    "\n",
    "            conf[n].plot(ax=ax[j, int(2 * i)], labels=['Sea', 'Oil', 'LoA', 'Ship', 'Land'], fontsize=35)\n",
    "            n += 1\n",
    "\n",
    "    figure.suptitle('DeepLabV3 predictions overlayed onto image with Prediction mask with corresponding confusionmatrix', fontsize=40, fontweight=\"bold\")\n",
    "    figure.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(\"C:/Users/Mr. Oliver/Desktop/CNN/FinalModels/UNet/checklabelimages\" + str(it) + \".png\")\n",
    "\n",
    "#Prediction of the model for the visualization\n",
    "def make_predictions(model, imagePath):\n",
    "\n",
    "    # Initialize evaluation metrics\n",
    "    ConfusionMatrix = MulticlassConfusionMatrix(num_classes=5, normalize=\"true\").to(config.device)\n",
    "    metric = JaccardIndex(task=\"multiclass\", num_classes=5, average=None).to(config.device)\n",
    "    Accuracy = MulticlassAccuracy(num_classes=5, average=None).to(config.device)\n",
    "    preprocess_input = get_preprocessing_fn('resnet101', pretrained='imagenet')\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Get ground truth mask path\n",
    "        filename = os.path.join(os.path.dirname(os.path.dirname(imagePath)), \"labels_1D\", os.path.splitext(os.path.basename(imagePath))[0] + \".png\")\n",
    "        groundTruthPath = os.path.join(file_path, config.train_label, filename)\n",
    "\n",
    "        # Read image and ground truth mask\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        gtMask = Image.open(groundTruthPath)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Convert image to PyTorch tensor\n",
    "        image = transforms.ToTensor()(image).type(torch.float)\n",
    "        x = torch.unsqueeze(image, dim=0)\n",
    "\n",
    "        # Calculate the amount of padding needed\n",
    "        target_height = ((x.size(2) + 31) // 32) * 32\n",
    "        target_width = ((x.size(3) + 31) // 32) * 32\n",
    "        padding_height = target_height - x.size(2)\n",
    "        padding_width = target_width - x.size(3)\n",
    "\n",
    "        # Apply zero-padding\n",
    "        padded_image = F.pad(x, (0, padding_width, 0, padding_height))\n",
    "        resized_image = transforms.Resize((target_height, target_width))(x)\n",
    "        #resized_image = transforms.Resize((320,320))(x)\n",
    "        #print(padded_image.size())\n",
    "        #\"\"\"\n",
    "        #################EMPATCHES\n",
    "        bp = BatchPatching(patchsize=320, overlap=0.3, stride=None, typ='torch')\n",
    "        # extracging\n",
    "        batch_patches, batch_indices = bp.patch_batch(x)\n",
    "        for i, patch in enumerate(batch_patches[0]):\n",
    "            patch = torch.unsqueeze(patch.permute(2,0,1), dim=0)\n",
    "            m = model(patch.to(config.device)).cpu()\n",
    "            batch_patches[0][i] = torch.squeeze(m, dim=0).permute(1,2,0)\n",
    "        \n",
    "        merged_batch = bp.merge_batch(batch_patches, batch_indices, mode='overwrite')\n",
    "        merged_batch = transforms.ToTensor()(np.squeeze(merged_batch, axis=0))\n",
    "        merged_batch = torch.unsqueeze(merged_batch.permute(1,0,2), dim=0)\n",
    "        #predMask = model(im)\n",
    "        ######\n",
    "        #\"\"\"\n",
    "\n",
    "        # Resize image and ground truth mask\n",
    "        #image = transforms.Resize((320, 320))(image)\n",
    "        #gtMask = transforms.Resize((320, 320), interpolation=transforms.InterpolationMode.NEAREST_EXACT)(gtMask)\n",
    "        #x = torch.unsqueeze(image, dim=0)\n",
    "        \n",
    "        # Preprocess input for model\n",
    "        #x = preprocess_input(x.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "        #x = torch.from_numpy(x.transpose(0, 3, 1, 2)).type(torch.FloatTensor).to(config.device)\n",
    "        #image = transforms.Resize((650, 1250))(image)\n",
    "        #gtMask = transforms.Resize((650, 1250), interpolation=transforms.InterpolationMode.NEAREST_EXACT)(gtMask)\n",
    "        gtMask = torch.squeeze(transforms.PILToTensor()(gtMask)).type(torch.int64)\n",
    "        testgtMask = gtMask\n",
    "        orig = image.cpu().detach().numpy().transpose(1, 2, 0).copy()\n",
    "\n",
    "        # Get predictions from the model\n",
    "        #predMask = model(padded_image.to(config.device))\n",
    "        #predMask = predMask[:, :, :650, :1250]\n",
    "        #predMask = model(resized_image.to(config.device))\n",
    "        #predMask = transforms.Resize((650, 1250), interpolation=transforms.InterpolationMode.BILINEAR)(predMask)\n",
    "\n",
    "       \n",
    "        \n",
    "        # Use argmax to get the index of the class with the highest probability\n",
    "        #predicted_classes = torch.argmax(predMask, dim=1)\n",
    "\n",
    "        # Create a binary mask based on the predicted class\n",
    "        #mask = torch.zeros_like(predMask)\n",
    "        #print(\"merged \", merged_batch)\n",
    "        # Use argmax to get the index of the class with the highest probability\n",
    "        predicted_classes = torch.argmax(merged_batch, dim=1)\n",
    "\n",
    "        # Create a binary mask based on the predicted class\n",
    "        mask = torch.zeros_like(merged_batch)\n",
    "        mask.scatter_(1, predicted_classes.unsqueeze(1), 1)\n",
    "\n",
    "        # Assign values based on the predicted class\n",
    "        background_value = 0\n",
    "        oil_spill_value = 1\n",
    "        look_alike_value = 2\n",
    "        ships_value = 3\n",
    "        land_value = 4\n",
    "\n",
    "        # Assign values based on the predicted class\n",
    "        result_image = (\n",
    "            mask[:, 0:1, :, :] * background_value +\n",
    "            mask[:, 1:2, :, :] * oil_spill_value +\n",
    "            mask[:, 2:3, :, :] * look_alike_value +\n",
    "            mask[:, 3:4, :, :] * ships_value +\n",
    "            mask[:, 4:5, :, :] * land_value\n",
    "        )\n",
    "\n",
    "        metric.update(torch.squeeze(result_image).to(\"cuda\"), testgtMask.to(\"cuda\"))\n",
    "        Accuracy.update(torch.squeeze(result_image).to(\"cuda\"), testgtMask.to(\"cuda\"))\n",
    "        ConfusionMatrix.update(torch.squeeze(result_image.type(torch.float32)).to(\"cuda\"), testgtMask.to(\"cuda\"))\n",
    "\n",
    "        # Store current confusion matrix\n",
    "        currConf = ConfusionMatrix\n",
    "        result_image = result_image.cpu().numpy()\n",
    "        result_image = result_image.astype(np.uint8)\n",
    "        \n",
    "        # Reset metrics for the next iteration\n",
    "        metric.reset()\n",
    "        Accuracy.reset()\n",
    "\n",
    "        return orig, gtMask, result_image, currConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0  #To keep track of what image i am looking at when going through them.\n",
    "iMPaths = np.array(sorted(list(paths.list_images(os.path.join(file_path, config.test_image)))))  #Collect the paths and sort them\n",
    "model = torch.load(os.path.join(file_path, config.model)).to(config.device)                      #The trainedm model\n",
    "while True:                                                                                      #Runs through all the images\n",
    "    prevIt = it\n",
    "    it +=8\n",
    "    imagepaths = iMPaths[prevIt:it]                                                              #Look at 8 images at a time\n",
    "    xlist, ylist, predlist, conflist = [], [], [], []\n",
    "    for path in imagepaths:\n",
    "        x, y, pred, conf = make_predictions(model, path)                                        #Predictions\n",
    "        xlist.append(x)\n",
    "        ylist.append(y)\n",
    "        predlist.append(pred)\n",
    "        conflist.append(conf)\n",
    "    \n",
    "    prepare_plot(xlist, ylist, predlist, conflist, it)                                          #Plots\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
